# ğŸ“ Checkpoint 2 â€“ Disruptive Architectures: IoT, IoB e Generative AI

## ğŸ‘¤ Aluno
**Nome:** Felipe Ulson Sora  
**RM:** 555462

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o dos exercÃ­cios de **classificaÃ§Ã£o multiclasse** e **regressÃ£o** usando **redes neurais em Keras** e modelos tradicionais do **scikit-learn**.  

---

## ğŸ· ExercÃ­cio 1 â€“ ClassificaÃ§Ã£o Multiclasse (Wine Dataset)

### ğŸ¯ Objetivo
Classificar vinhos em 3 classes diferentes com base em 13 atributos quÃ­micos.

### ğŸ› ï¸ Modelos Utilizados
- **Rede Neural (Keras)**:
  - 2 camadas ocultas com 32 neurÃ´nios cada (ReLU)
  - Camada de saÃ­da com 3 neurÃ´nios (Softmax)
  - Perda: categorical_crossentropy
  - Otimizador: Adam
- **RandomForestClassifier (Scikit-learn)**
- **LogisticRegression (Scikit-learn)**

### âš™ï¸ PrÃ©-processamento
- NormalizaÃ§Ã£o dos atributos com `StandardScaler`
- One-hot encoding das classes para a rede neural
- DivisÃ£o em treino/teste (80/20)

### ğŸ“Š Resultados
| Modelo                | AcurÃ¡cia |
|-----------------------|----------|
| Rede Neural (Keras)   | 1.0000   |
| RandomForest          | 1.0000   |
| Logistic Regression   | 1.0000   |

### ğŸ“ DiscussÃ£o
- Todos os modelos atingiram acurÃ¡cia perfeita no conjunto de teste, mostrando que o **Wine Dataset** possui atributos altamente discriminativos.  
- A **RandomForest** e a **Logistic Regression** sÃ£o mais rÃ¡pidas e simples, enquanto a **rede neural** Ã© mais flexÃ­vel e aplicÃ¡vel a problemas mais complexos.  
- Apesar da alta acurÃ¡cia, recomenda-se validaÃ§Ã£o cruzada em datasets pequenos para evitar overfitting e obter uma avaliaÃ§Ã£o mais confiÃ¡vel.

---

## ğŸ  ExercÃ­cio 2 â€“ RegressÃ£o (California Housing Dataset)

### ğŸ¯ Objetivo
Prever o valor mÃ©dio das casas na CalifÃ³rnia com base em 8 atributos.

### ğŸ› ï¸ Modelos Utilizados
- **Rede Neural (Keras)**:
  - 3 camadas ocultas: 64, 32 e 16 neurÃ´nios (ReLU)
  - Camada de saÃ­da com 1 neurÃ´nio (Linear)
  - Perda: MSE
  - Otimizador: Adam
- **LinearRegression (Scikit-learn)**
- **RandomForestRegressor (Scikit-learn)**

### âš™ï¸ PrÃ©-processamento
- NormalizaÃ§Ã£o dos atributos com `StandardScaler`
- DivisÃ£o em treino/teste (80/20)

### ğŸ“Š Resultados
| Modelo                | MSE     | MAE    |
|-----------------------|---------|--------|
| Rede Neural (Keras)   | 0.27    | 0.34   |
| Linear Regression     | 0.50    | 0.54   |
| RandomForest Regressor| 0.26    | 0.33   |

### ğŸ“ DiscussÃ£o
- O **RandomForest Regressor** apresentou o melhor desempenho, com os menores valores de erro.  
- A **Rede Neural** conseguiu resultados prÃ³ximos, mas poderia ser otimizada com mais Ã©pocas, regularizaÃ§Ã£o ou ajuste de hiperparÃ¢metros.  
- A **Linear Regression** teve desempenho inferior, devido Ã  sua limitaÃ§Ã£o em capturar relaÃ§Ãµes nÃ£o lineares entre variÃ¡veis.  
- ConclusÃ£o: Para dados tabulares estruturados, **modelos baseados em Ã¡rvores** (RandomForest) costumam superar redes neurais simples.

---

## ğŸ’¡ ObservaÃ§Ãµes Finais
- Foram aplicadas tÃ©cnicas de **normalizaÃ§Ã£o e encoding** para melhorar o desempenho dos modelos.  
- O repositÃ³rio serve como referÃªncia de comparaÃ§Ã£o entre **modelos de redes neurais** e **modelos tradicionais do scikit-learn** em problemas de **classificaÃ§Ã£o e regressÃ£o**.
