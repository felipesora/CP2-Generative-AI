# ğŸ“ Checkpoint 2 â€“ Disruptive Architectures: IoT, IoB e Generative AI

## ğŸ‘¤ Aluno
**Nome:** Felipe Ulson Sora  
**RM:** 555462

## ğŸ’¾ DescriÃ§Ã£o do RepositÃ³rio

Este repositÃ³rio contÃ©m as implementaÃ§Ãµes dos exercÃ­cios desenvolvidos na disciplina **Disruptive Architectures: IoT, IoB e Generative AI**, divididos em duas partes:

- **Parte 01 â€“ Redes Neurais**: aplicaÃ§Ãµes de **classificaÃ§Ã£o multiclasse** e **regressÃ£o** utilizando **redes neurais com Keras** e modelos tradicionais do **Scikit-learn**.

- **Parte 02 â€“ VisÃ£o Computacional**: uso de **modelos prÃ©-treinados** do **Hugging Face** e do **YOLOv8** para **classificaÃ§Ã£o e detecÃ§Ã£o de objetos em imagens** (cÃ£es e gatos).

O projeto compara **diferentes abordagens de aprendizado de mÃ¡quina e deep learning**, explorando desde **dados tabulares** atÃ© **imagens reais**.

---

## ğŸ¤– Parte 01 - Redes Neurais

### ğŸ· ExercÃ­cio 1 â€“ ClassificaÃ§Ã£o Multiclasse (Wine Dataset)

#### ğŸ¯ Objetivo
Classificar vinhos em 3 classes diferentes com base em 13 atributos quÃ­micos.

#### ğŸ› ï¸ Modelos Utilizados
- **Rede Neural (Keras)**:
  - 2 camadas ocultas com 32 neurÃ´nios cada (ReLU)
  - Camada de saÃ­da com 3 neurÃ´nios (Softmax)
  - Perda: categorical_crossentropy
  - Otimizador: Adam
- **RandomForestClassifier (Scikit-learn)**
- **LogisticRegression (Scikit-learn)**

#### âš™ï¸ PrÃ©-processamento
- NormalizaÃ§Ã£o dos atributos com `StandardScaler`
- One-hot encoding das classes para a rede neural
- DivisÃ£o em treino/teste (80/20)

#### ğŸ“Š Resultados
| Modelo                | AcurÃ¡cia |
|-----------------------|----------|
| Rede Neural (Keras)   | 1.0000   |
| RandomForest          | 1.0000   |
| Logistic Regression   | 1.0000   |

#### ğŸ“ DiscussÃ£o
- Todos os modelos atingiram acurÃ¡cia perfeita no conjunto de teste, mostrando que o **Wine Dataset** possui atributos altamente discriminativos.  
- A **RandomForest** e a **Logistic Regression** sÃ£o mais rÃ¡pidas e simples, enquanto a **rede neural** Ã© mais flexÃ­vel e aplicÃ¡vel a problemas mais complexos.  
- Apesar da alta acurÃ¡cia, recomenda-se validaÃ§Ã£o cruzada em datasets pequenos para evitar overfitting e obter uma avaliaÃ§Ã£o mais confiÃ¡vel.

### ğŸ  ExercÃ­cio 2 â€“ RegressÃ£o (California Housing Dataset)

#### ğŸ¯ Objetivo
Prever o valor mÃ©dio das casas na CalifÃ³rnia com base em 8 atributos.

#### ğŸ› ï¸ Modelos Utilizados
- **Rede Neural (Keras)**:
  - 3 camadas ocultas: 64, 32 e 16 neurÃ´nios (ReLU)
  - Camada de saÃ­da com 1 neurÃ´nio (Linear)
  - Perda: MSE
  - Otimizador: Adam
- **LinearRegression (Scikit-learn)**
- **RandomForestRegressor (Scikit-learn)**

#### âš™ï¸ PrÃ©-processamento
- NormalizaÃ§Ã£o dos atributos com `StandardScaler`
- DivisÃ£o em treino/teste (80/20)

#### ğŸ“Š Resultados
| Modelo                | MSE     | MAE    |
|-----------------------|---------|--------|
| Rede Neural (Keras)   | 0.27    | 0.34   |
| Linear Regression     | 0.50    | 0.54   |
| RandomForest Regressor| 0.26    | 0.33   |

#### ğŸ“ DiscussÃ£o
- O **RandomForest Regressor** apresentou o melhor desempenho, com os menores valores de erro.  
- A **Rede Neural** conseguiu resultados prÃ³ximos, mas poderia ser otimizada com mais Ã©pocas, regularizaÃ§Ã£o ou ajuste de hiperparÃ¢metros.  
- A **Linear Regression** teve desempenho inferior, devido Ã  sua limitaÃ§Ã£o em capturar relaÃ§Ãµes nÃ£o lineares entre variÃ¡veis.  
- ConclusÃ£o: Para dados tabulares estruturados, **modelos baseados em Ã¡rvores** (RandomForest) costumam superar redes neurais simples.

### ğŸ’¡ ObservaÃ§Ãµes Finais
- Foram aplicadas tÃ©cnicas de **normalizaÃ§Ã£o e encoding** para melhorar o desempenho dos modelos.  
- O repositÃ³rio serve como referÃªncia de comparaÃ§Ã£o entre **modelos de redes neurais** e **modelos tradicionais do scikit-learn** em problemas de **classificaÃ§Ã£o e regressÃ£o**.

--- 

## ğŸ§  Parte 02 - VisÃ£o Computacional

### ğŸ¯ Objetivo

Explorar tÃ©cnicas de **classificaÃ§Ã£o e detecÃ§Ã£o de imagens** utilizando duas ferramentas de VisÃ£o Computacional distintas â€” **Hugging Face e YOLOv8** â€” para comparar seus resultados em imagens contendo **cÃ£es e gatos**.

### âš™ï¸ Ferramentas Utilizadas

#### ğŸ§© 1. Hugging Face â€“ Vision Transformer (ViT)

- Modelo: `google/vit-base-patch16-224`

- Tarefa: **ClassificaÃ§Ã£o de imagem**

- O modelo foi prÃ©-treinado em milhÃµes de imagens, sendo capaz de identificar a classe mais provÃ¡vel de um objeto em uma imagem completa.

- Utilizado por meio do `pipeline("image-classification")` da biblioteca `transformers`.

#### ğŸ§  2. YOLOv8 â€“ Ultralytics

- Modelo: `yolov8n.pt` (versÃ£o leve prÃ©-treinada no COCO Dataset)

- Tarefa: **DetecÃ§Ã£o de objetos**

- Identifica e localiza objetos dentro de uma imagem, desenhando caixas delimitadoras (bounding boxes) e mostrando o nÃ­vel de confianÃ§a de cada detecÃ§Ã£o.

### ğŸ¾ Conjunto de Imagens

Foram utilizadas trÃªs imagens contendo cÃ£es e gatos em diferentes contextos:

- `gato02.jpg` â†’ apenas um gato

- `cachorros.jpg` â†’ mÃºltiplos cÃ£es

- `cachorro_gato.jpg` â†’ cÃ£o e gato juntos

Essas imagens foram fornecidas em aula e representam um cenÃ¡rio ideal para comparar **classificaÃ§Ã£o global (Hugging Face)** e **detecÃ§Ã£o localizada (YOLO)**.

### ğŸ” Metodologia

O notebook executa as seguintes etapas:

**1. InstalaÃ§Ã£o das bibliotecas**: `ultralytics`, `transformers`, `torch`, `pillow` e `opencv-python-headless`.

**2. ClassificaÃ§Ã£o (Hugging Face)**:
    - Cada imagem Ã© processada por um modelo de Transformer visual (ViT) para prever a classe principal (ex: Egyptian cat, Labrador, etc.).

**3. DetecÃ§Ã£o (YOLOv8)**:
    - O modelo YOLOv8 Ã© aplicado Ã s mesmas imagens, retornando as classes detectadas (ex: cat, dog) e desenhando caixas delimitadoras.

**4. VisualizaÃ§Ã£o e ComparaÃ§Ã£o**:
    - As imagens resultantes sÃ£o exibidas diretamente no notebook com as detecÃ§Ãµes visuais.
    - Os resultados textuais de ambas as abordagens sÃ£o exibidos lado a lado.

### ğŸ“Š Resultados Obtidos

| Imagem            | Hugging Face (ClassificaÃ§Ã£o) | YOLOv8 (DetecÃ§Ã£o)                       |
| ----------------- | ---------------------------- | --------------------------------------- |
| gato02.jpg        | *Egyptian cat* (0.25)        | 1 gato detectado (0.85)                 |
| cachorros.jpg     | *kelpie* (0.48)              | 3 cÃ£es detectados (0.91, 0.87, 0.77)    |
| cachorro_gato.jpg | *redbone* (0.78)             | 1 cÃ£o (0.76) e 1 gato (0.75) detectados |

### ğŸ“ DiscussÃ£o dos Resultados

- O **modelo do Hugging Face** foi eficaz em **classificar o tipo de animal predominante** na imagem, mas nÃ£o distingue mÃºltiplos objetos simultaneamente. Ele trata a imagem como um todo (visÃ£o global).

- O **YOLOv8**, por outro lado, conseguiu **detectar e localizar vÃ¡rios animais na mesma imagem**, mostrando sua forÃ§a em **detecÃ§Ã£o de objetos**.
Ele fornece informaÃ§Ãµes espaciais (posiÃ§Ã£o e quantidade).

- As diferenÃ§as refletem dois paradigmas distintos da VisÃ£o Computacional:

    - **ClassificaÃ§Ã£o**: â€œO que hÃ¡ nesta imagem?â€

    - **DetecÃ§Ã£o**: â€œO que hÃ¡ e onde estÃ¡?â€

- Em imagens simples (um Ãºnico animal), ambos os modelos tiveram respostas coerentes.

- Em imagens com **mÃºltiplos animais**, o **YOLOv8** se mostrou mais completo, enquanto o **Hugging Face** identificou apenas uma categoria dominante.

### ğŸ’¡ ConclusÃ£o

- A combinaÃ§Ã£o de **Hugging Face (ViT)** e **YOLOv8** permitiu comparar abordagens complementares da VisÃ£o Computacional.

- O **Hugging Face** se destaca pela **simplicidade e precisÃ£o em classificaÃ§Ã£o geral**, enquanto o **YOLOv8** Ã© mais poderoso para **detecÃ§Ã£o e anÃ¡lise em tempo real**.

- Esse experimento demonstra como diferentes arquiteturas de IA podem ser aplicadas a um mesmo problema, revelando a **diversidade de aplicaÃ§Ãµes da VisÃ£o Computacional** em sistemas inteligentes.